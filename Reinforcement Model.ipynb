{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Project_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaswanthBadvelu/Reinforcement-Learning-CVRP/blob/main/Reinforcement%20Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yyoCQQDDHnh"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zQIUdwwKWWq"
      },
      "source": [
        "!pip install ortools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKFcHNxTDGH-"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "class AgentVRP():\n",
        "\n",
        "    VEHICLE_CAPACITY = 1.0\n",
        "\n",
        "    def __init__(self, input):\n",
        "\n",
        "        depot = input[0]\n",
        "        loc = input[1]\n",
        "\n",
        "        self.batch_size, self.n_loc, _ = loc.shape  # (batch_size, n_nodes, 2)\n",
        "\n",
        "        # Coordinates of depot + other nodes\n",
        "        self.coords = tf.concat((depot[:, None, :], loc), -2)\n",
        "        self.demand = tf.cast(input[2], tf.float32)\n",
        "\n",
        "        # Indices of graphs in batch\n",
        "        self.ids = tf.range(self.batch_size, dtype=tf.int64)[:, None]\n",
        "\n",
        "        # State\n",
        "        self.prev_a = tf.zeros((self.batch_size, 1), dtype=tf.float32)\n",
        "        self.from_depot = self.prev_a == 0\n",
        "        self.used_capacity = tf.zeros((self.batch_size, 1), dtype=tf.float32)\n",
        "\n",
        "        # Nodes that have been visited will be marked with 1\n",
        "        self.visited = tf.zeros((self.batch_size, 1, self.n_loc + 1), dtype=tf.uint8)\n",
        "\n",
        "        # Step counter\n",
        "        self.i = tf.zeros(1, dtype=tf.int64)\n",
        "\n",
        "        # Constant tensors for scatter update (in step method)\n",
        "        self.step_updates = tf.ones((self.batch_size, 1), dtype=tf.uint8)  # (batch_size, 1)\n",
        "        self.scatter_zeros = tf.zeros((self.batch_size, 1), dtype=tf.int64)  # (batch_size, 1)\n",
        "\n",
        "    @staticmethod\n",
        "    def outer_pr(a, b):\n",
        "        \"\"\"Outer product of matrices\n",
        "        \"\"\"\n",
        "        return tf.einsum('ki,kj->kij', a, b)\n",
        "\n",
        "    def get_att_mask(self):\n",
        "        \"\"\" Mask (batch_size, n_nodes, n_nodes) for attention encoder.\n",
        "            We mask already visited nodes except depot\n",
        "        \"\"\"\n",
        "\n",
        "        # We dont want to mask depot\n",
        "        att_mask = tf.squeeze(tf.cast(self.visited, tf.float32), axis=-2)[:, 1:]  # [batch_size, 1, n_nodes] --> [batch_size, n_nodes-1]\n",
        "        \n",
        "        # Number of nodes in new instance after masking\n",
        "        cur_num_nodes = self.n_loc + 1 - tf.reshape(tf.reduce_sum(att_mask, -1), (-1,1))  # [batch_size, 1]\n",
        "        \n",
        "        att_mask = tf.concat((tf.zeros(shape=(att_mask.shape[0],1),dtype=tf.float32),att_mask), axis=-1)\n",
        "\n",
        "        ones_mask = tf.ones_like(att_mask)\n",
        "\n",
        "        # Create square attention mask from row-like mask\n",
        "        att_mask = AgentVRP.outer_pr(att_mask, ones_mask) \\\n",
        "                            + AgentVRP.outer_pr(ones_mask, att_mask)\\\n",
        "                            - AgentVRP.outer_pr(att_mask, att_mask)\n",
        "        \n",
        "        return tf.cast(att_mask, dtype=tf.bool), cur_num_nodes\n",
        "\n",
        "    def all_finished(self):\n",
        "        \"\"\"Checks if all games are finished\n",
        "        \"\"\"\n",
        "        return tf.reduce_all(tf.cast(self.visited, tf.bool))\n",
        "\n",
        "    def partial_finished(self):\n",
        "        \"\"\"Checks if partial solution for all graphs has been built, i.e. all agents came back to depot\n",
        "        \"\"\"\n",
        "        return tf.reduce_all(self.from_depot) and self.i != 0\n",
        "\n",
        "    def get_mask(self):\n",
        "        \"\"\" Returns a mask (batch_size, 1, n_nodes) with available actions.\n",
        "            Impossible nodes are masked.\n",
        "        \"\"\"\n",
        "\n",
        "        # Exclude depot\n",
        "        visited_loc = self.visited[:, :, 1:]\n",
        "\n",
        "        # Mark nodes which exceed vehicle capacity\n",
        "        exceeds_cap = self.demand + self.used_capacity > self.VEHICLE_CAPACITY\n",
        "\n",
        "        # We mask nodes that are already visited or have too much demand\n",
        "        # Also for dynamical model we stop agent at depot when it arrives there (for partial solution)\n",
        "        mask_loc = tf.cast(visited_loc, tf.bool) | exceeds_cap[:, None, :] | ((self.i > 0) & self.from_depot[:, None, :])\n",
        "\n",
        "        # We can choose depot if 1) we are not in depot OR 2) all nodes are visited\n",
        "        mask_depot = self.from_depot & (tf.reduce_sum(tf.cast(mask_loc == False, tf.int32), axis=-1) > 0)\n",
        "\n",
        "        return tf.concat([mask_depot[:, :, None], mask_loc], axis=-1)\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        # Update current state\n",
        "        selected = action[:, None]\n",
        "\n",
        "        self.prev_a = selected\n",
        "        self.from_depot = self.prev_a == 0\n",
        "\n",
        "        # We have to shift indices by 1 since demand doesn't include depot\n",
        "        # 0-index in demand corresponds to the FIRST node\n",
        "        selected_demand = tf.gather_nd(self.demand,\n",
        "                                       tf.concat([self.ids, tf.clip_by_value(self.prev_a - 1, 0, self.n_loc - 1)], axis=1)\n",
        "                                       )[:, None]  # (batch_size, 1)\n",
        "\n",
        "        # We add current node capacity to used capacity and set it to zero if we return to the depot\n",
        "        self.used_capacity = (self.used_capacity + selected_demand) * (1.0 - tf.cast(self.from_depot, tf.float32))\n",
        "\n",
        "        # Update visited nodes (set 1 to visited nodes)\n",
        "        idx = tf.cast(tf.concat((self.ids, self.scatter_zeros, self.prev_a), axis=-1), tf.int32)[:, None, :]  # (batch_size, 1, 3)\n",
        "        self.visited = tf.tensor_scatter_nd_update(self.visited, idx, self.step_updates)  # (batch_size, 1, n_nodes)\n",
        "\n",
        "        self.i = self.i + 1\n",
        "\n",
        "    @staticmethod\n",
        "    def get_costs(dataset, pi):\n",
        "\n",
        "        # Place nodes with coordinates in order of decoder tour\n",
        "        loc_with_depot = tf.concat([dataset[0][:, None, :], dataset[1]], axis=1)  # (batch_size, n_nodes, 2)\n",
        "        d = tf.gather(loc_with_depot, tf.cast(pi, tf.int32), batch_dims=1)\n",
        "\n",
        "        # Calculation of total distance\n",
        "        # Note: first element of pi is not depot, but the first selected node in the path\n",
        "        return (tf.reduce_sum(tf.norm(d[:, 1:] - d[:, :-1], ord='euclidean', axis=2), axis=1)# Changed from ord=2 to euclidean\n",
        "                + tf.norm(d[:, 0] - dataset[0], ord='euclidean', axis=1) # Distance from depot to first selected node\n",
        "                + tf.norm(d[:, -1] - dataset[0], ord='euclidean', axis=1))  # Distance from last selected node (!=0 for graph with longest path) to depot"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTBiGDtDDUGe"
      },
      "source": [
        "# Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9TJ3KX1DNOM"
      },
      "source": [
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    \"\"\" Attention Layer - multi-head scaled dot product attention (for encoder and decoder)\n",
        "        Args:\n",
        "            num_heads: number of attention heads which will be computed in parallel\n",
        "            d_model: embedding size of output features\n",
        "        Call arguments:\n",
        "            q: query, shape (..., seq_len_q, depth_q)\n",
        "            k: key, shape == (..., seq_len_k, depth_k)\n",
        "            v: value, shape == (..., seq_len_v, depth_v)\n",
        "            mask: Float tensor with shape broadcastable to (..., seq_len_q, seq_len_k) or None.\n",
        "            Since we use scaled-product attention, we assume seq_len_k = seq_len_v\n",
        "        Returns:\n",
        "              attention outputs of shape (batch_size, seq_len_q, d_model)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_heads, d_model, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.n_heads = n_heads\n",
        "        self.d_model = d_model\n",
        "        self.head_depth = self.d_model // self.n_heads\n",
        "\n",
        "        if self.d_model % self.n_heads != 0:\n",
        "            raise ValueError(\"number of heads must divide d_model\")\n",
        "\n",
        "        # define weight matrices\n",
        "        self.wq = tf.keras.layers.Dense(self.d_model, use_bias=False)  # (d_q, d_model)\n",
        "        self.wk = tf.keras.layers.Dense(self.d_model, use_bias=False)  # (d_k, d_model)\n",
        "        self.wv = tf.keras.layers.Dense(self.d_model, use_bias=False)  # (d_v, d_model)\n",
        "\n",
        "        self.w_out = tf.keras.layers.Dense(self.d_model, use_bias=False)  # (d_model, d_model)\n",
        "\n",
        "    def split_heads(self, tensor, batch_size):\n",
        "        \"\"\"Function for computing attention on several heads simultaneously\n",
        "        Splits last dimension of a tensor into (num_heads, head_depth).\n",
        "        Then we transpose it as (batch_size, num_heads, ..., head_depth) so that we can use broadcast\n",
        "        \"\"\"\n",
        "        tensor = tf.reshape(tensor, (batch_size, -1, self.n_heads, self.head_depth))\n",
        "        return tf.transpose(tensor, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # treats first parameter q as input, and  k, v as parameters, so input_shape=q.shape\n",
        "    def call(self, q, k, v, mask=None):\n",
        "        # shape of q: (batch_size, seq_len_q, d_q)\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        # compute Q = q * w_q, ...\n",
        "        Q = self.wq(q)  # (batch_size, seq_len_q, d_q) x (d_q, d_model) --> (batch_size, seq_len_q, d_model)\n",
        "        K = self.wk(k)  # ... --> (batch_size, seq_len_k, d_model)\n",
        "        V = self.wv(v)  # ... --> (batch_size, seq_len_v, d_model)\n",
        "\n",
        "        # split heads: d_model = num_heads * head_depth + reshape\n",
        "        Q = self.split_heads(Q, batch_size)  # (batch_size, num_heads, seq_len_q, head_depth)\n",
        "        K = self.split_heads(K, batch_size)  # (batch_size, num_heads, seq_len_k, head_depth)\n",
        "        V = self.split_heads(V, batch_size)  # (batch_size, num_heads, seq_len_v, head_depth)\n",
        "\n",
        "        # similarity between context vector Q and key K // self-similarity in case of self-attention\n",
        "        compatibility = tf.matmul(Q, K, transpose_b=True)  # (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "                                                           # seq_len_q = n_nodes for encoder self-attention\n",
        "                                                           # seq_len_q = 1 for decoder context-vector attention\n",
        "                                                           # seq_len_k = n_nodes for both encoder & decoder\n",
        "        # rescaling\n",
        "        dk = tf.cast(tf.shape(K)[-1], tf.float32)\n",
        "        compatibility = compatibility / tf.math.sqrt(dk)\n",
        "\n",
        "        if mask is not None:\n",
        "            # we need to reshape mask:\n",
        "            # (batch_size, seq_len_q, seq_len_k) --> (batch_size, 1, seq_len_q, seq_len_k)\n",
        "            # so that we will be able to do a broadcast:\n",
        "            # (batch_size, num_heads, seq_len_q, seq_len_k) + (batch_size, 1, seq_len_q, seq_len_k)\n",
        "            mask = mask[:, tf.newaxis, :, :]\n",
        "\n",
        "            # we use tf.where since 0*-np.inf returns nan, but not -np.inf\n",
        "            # compatibility = tf.where(\n",
        "            #                     tf.broadcast_to(mask, compatibility.shape), tf.ones_like(compatibility) * (-np.inf),\n",
        "            #                     compatibility\n",
        "            #                      )\n",
        "\n",
        "            compatibility = tf.where(mask,\n",
        "                                    tf.ones_like(compatibility) * (-np.inf),\n",
        "                                    compatibility)\n",
        "\n",
        "        compatibility = tf.nn.softmax(compatibility, axis=-1)  # (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "\n",
        "        # Replace NaN by zeros (tf.nn.softmax returns NaNs for masked rows)\n",
        "        compatibility = tf.where(tf.math.is_nan(compatibility), tf.zeros_like(compatibility), compatibility)\n",
        "\n",
        "        # seq_len_k = seq_len_v\n",
        "        attention = tf.matmul(compatibility, V)  # (batch_size, num_heads, seq_len_q, head_depth)\n",
        "\n",
        "        # transpose back to (batch_size, seq_len_q, num_heads, head_depth)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        # concatenate heads (last 2 dimensions)\n",
        "        attention = tf.reshape(attention, (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        # project output to the same dimension\n",
        "        # this is equiv. to sum in the article (project heads with W_o and sum), beacuse of block-matrix multiplication\n",
        "        #e.g. https://math.stackexchange.com/questions/2961550/matrix-block-multiplication-definition-properties-and-applications\n",
        "\n",
        "        output = self.w_out(attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_QeLs5IDrPH"
      },
      "source": [
        "# Graph Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPYFMaTLDYEb"
      },
      "source": [
        "\n",
        "#from layers import MultiHeadAttention\n",
        "\n",
        "\n",
        "class MultiHeadAttentionLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"Feed-Forward Sublayer: fully-connected Feed-Forward network,\n",
        "    built based on MHA vectors from MultiHeadAttention layer with skip-connections\n",
        "        Args:\n",
        "            num_heads: number of attention heads in MHA layers.\n",
        "            input_dim: embedding size that will be used as d_model in MHA layers.\n",
        "            feed_forward_hidden: number of neuron units in each FF layer.\n",
        "        Call arguments:\n",
        "            x: batch of shape (batch_size, n_nodes, node_embedding_size).\n",
        "            mask: mask for MHA layer\n",
        "        Returns:\n",
        "               outputs of shape (batch_size, n_nodes, input_dim)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, num_heads, feed_forward_hidden=512, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.mha = MultiHeadAttention(n_heads=num_heads, d_model=input_dim, name='MHA')\n",
        "        self.ff1 = tf.keras.layers.Dense(feed_forward_hidden, name='ff1')\n",
        "        self.ff2 = tf.keras.layers.Dense(input_dim, name='ff2')\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        mha_out = self.mha(x, x, x, mask)\n",
        "        sc1_out = tf.keras.layers.Add()([x, mha_out])\n",
        "        tanh1_out = tf.keras.activations.tanh(sc1_out)\n",
        "\n",
        "        ff1_out = self.ff1(tanh1_out)\n",
        "        relu1_out = tf.keras.activations.relu(ff1_out)\n",
        "        ff2_out = self.ff2(relu1_out)\n",
        "        sc2_out = tf.keras.layers.Add()([tanh1_out, ff2_out])\n",
        "        tanh2_out = tf.keras.activations.tanh(sc2_out)\n",
        "\n",
        "        return tanh2_out\n",
        "\n",
        "class GraphAttentionEncoder(tf.keras.layers.Layer):\n",
        "    \"\"\"Graph Encoder, which uses MultiHeadAttentionLayer sublayer.\n",
        "        Args:\n",
        "            input_dim: embedding size that will be used as d_model in MHA layers.\n",
        "            num_heads: number of attention heads in MHA layers.\n",
        "            num_layers: number of attention layers that will be used in encoder.\n",
        "            feed_forward_hidden: number of neuron units in each FF layer.\n",
        "        Call arguments:\n",
        "            x: tuples of 3 tensors:  (batch_size, 2), (batch_size, n_nodes-1, 2), (batch_size, n_nodes-1)\n",
        "            First tensor contains coordinates for depot, second one is for coordinates of other nodes,\n",
        "            Last tensor is for normalized demands for nodes except depot\n",
        "            mask: mask for MHA layer\n",
        "        Returns:\n",
        "               Embedding for all nodes + mean embedding for graph.\n",
        "               Tuples ((batch_size, n_nodes, input_dim), (batch_size, input_dim))\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, num_heads, num_layers, feed_forward_hidden=512):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.num_heads = num_heads\n",
        "        self.feed_forward_hidden = feed_forward_hidden\n",
        "\n",
        "        # initial embeddings (batch_size, n_nodes-1, 2) --> (batch-size, input_dim), separate for depot and other nodes\n",
        "        self.init_embed_depot = tf.keras.layers.Dense(self.input_dim, name='init_embed_depot')  # nn.Linear(2, embedding_dim)\n",
        "        self.init_embed = tf.keras.layers.Dense(self.input_dim, name='init_embed')\n",
        "\n",
        "        self.mha_layers = [MultiHeadAttentionLayer(self.input_dim, self.num_heads, self.feed_forward_hidden)\n",
        "                            for _ in range(self.num_layers)]\n",
        "\n",
        "    def call(self, x, mask=None, cur_num_nodes=None):\n",
        "\n",
        "        x = tf.concat((self.init_embed_depot(x[0])[:, None, :],  # (batch_size, 2) --> (batch_size, 1, 2)\n",
        "                       self.init_embed(tf.concat((x[1], x[2][:, :, None]), axis=-1))  # (batch_size, n_nodes-1, 2) + (batch_size, n_nodes-1)\n",
        "                       ), axis=1)  # (batch_size, n_nodes, input_dim)\n",
        "\n",
        "        # stack attention layers\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.mha_layers[i](x, mask)\n",
        "\n",
        "        if mask is not None:\n",
        "            output = (x, tf.reduce_sum(x, axis=1) / cur_num_nodes)\n",
        "        else:\n",
        "            output = (x, tf.reduce_mean(x, axis=1))\n",
        "            \n",
        "        return output # (embeds of nodes, avg graph embed)=((batch_size, n_nodes, input), (batch_size, input_dim))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDR6YeZiEJqj"
      },
      "source": [
        "# Attention Dynamic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QdoVgHyEBHS"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "#from attention_graph_encoder import GraphAttentionEncoder\n",
        "#from enviroment import AgentVRP\n",
        "\n",
        "\n",
        "def set_decode_type(model, decode_type):\n",
        "    model.set_decode_type(decode_type)\n",
        "\n",
        "class AttentionDynamicModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self,\n",
        "                 embedding_dim,\n",
        "                 n_encode_layers=3,\n",
        "                 n_heads=8,\n",
        "                 tanh_clipping=10.\n",
        "                 ):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # attributes for MHA\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.n_encode_layers = n_encode_layers\n",
        "        self.decode_type = None\n",
        "\n",
        "        # attributes for VRP problem\n",
        "        self.problem = AgentVRP\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        # Encoder part\n",
        "        self.embedder = GraphAttentionEncoder(input_dim=self.embedding_dim,\n",
        "                                              num_heads=self.n_heads,\n",
        "                                              num_layers=self.n_encode_layers\n",
        "                                              )\n",
        "\n",
        "        # Decoder part\n",
        "\n",
        "        self.output_dim = self.embedding_dim\n",
        "        self.num_heads = n_heads\n",
        "\n",
        "        self.head_depth = self.output_dim // self.num_heads\n",
        "        self.dk_mha_decoder = tf.cast(self.head_depth, tf.float32)  # for decoding in mha_decoder\n",
        "        self.dk_get_loc_p = tf.cast(self.output_dim, tf.float32)  # for decoding in mha_decoder\n",
        "\n",
        "        if self.output_dim % self.num_heads != 0:\n",
        "            raise ValueError(\"number of heads must divide d_model=output_dim\")\n",
        "\n",
        "        self.tanh_clipping = tanh_clipping\n",
        "\n",
        "        # we split projection matrix Wq into 2 matrices: Wq*[h_c, h_N, D] = Wq_context*h_c + Wq_step_context[h_N, D]\n",
        "        self.wq_context = tf.keras.layers.Dense(self.output_dim, use_bias=False,\n",
        "                                                name='wq_context')  # (d_q_context, output_dim)\n",
        "        self.wq_step_context = tf.keras.layers.Dense(self.output_dim, use_bias=False,\n",
        "                                                     name='wq_step_context')  # (d_q_step_context, output_dim)\n",
        "\n",
        "        # we need two Wk projections since there is MHA followed by 1-head attention - they have different keys K\n",
        "        self.wk = tf.keras.layers.Dense(self.output_dim, use_bias=False, name='wk')  # (d_k, output_dim)\n",
        "        self.wk_tanh = tf.keras.layers.Dense(self.output_dim, use_bias=False, name='wk_tanh')  # (d_k_tanh, output_dim)\n",
        "\n",
        "        # we dont need Wv projection for 1-head attention: only need attention weights as outputs\n",
        "        self.wv = tf.keras.layers.Dense(self.output_dim, use_bias=False, name='wv')  # (d_v, output_dim)\n",
        "\n",
        "        # we dont need wq for 1-head tanh attention, since we can absorb it into w_out\n",
        "        self.w_out = tf.keras.layers.Dense(self.output_dim, use_bias=False, name='w_out')  # (d_model, d_model)\n",
        "\n",
        "    def set_decode_type(self, decode_type):\n",
        "        self.decode_type = decode_type\n",
        "\n",
        "    def split_heads(self, tensor, batch_size):\n",
        "        \"\"\"Function for computing attention on several heads simultaneously\n",
        "        Splits last dimension of a tensor into (num_heads, head_depth).\n",
        "        Then we transpose it as (batch_size, num_heads, ..., head_depth) so that we can use broadcast\n",
        "        \"\"\"\n",
        "        tensor = tf.reshape(tensor, (batch_size, -1, self.num_heads, self.head_depth))\n",
        "        return tf.transpose(tensor, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def _select_node(self, logits):\n",
        "        \"\"\"Select next node based on decoding type.\n",
        "        \"\"\"\n",
        "\n",
        "        # assert tf.reduce_all(logits == logits), \"Probs should not contain any nans\"\n",
        "\n",
        "        if self.decode_type == \"greedy\":\n",
        "            selected = tf.math.argmax(logits, axis=-1)  # (batch_size, 1)\n",
        "\n",
        "        elif self.decode_type == \"sampling\":\n",
        "            # logits has a shape of (batch_size, 1, n_nodes), we have to squeeze it\n",
        "            # to (batch_size, n_nodes) since tf.random.categorical requires matrix\n",
        "            selected = tf.random.categorical(logits[:, 0, :], 1)  # (bach_size,1)\n",
        "        else:\n",
        "            assert False, \"Unknown decode type\"\n",
        "\n",
        "        return tf.squeeze(selected, axis=-1)  # (bach_size,)\n",
        "\n",
        "    def get_step_context(self, state, embeddings):\n",
        "        \"\"\"Takes a state and graph embeddings,\n",
        "           Returns a part [h_N, D] of context vector [h_c, h_N, D],\n",
        "           that is related to RL Agent last step.\n",
        "        \"\"\"\n",
        "        # index of previous node\n",
        "        prev_node = state.prev_a  # (batch_size, 1)\n",
        "\n",
        "        # from embeddings=(batch_size, n_nodes, input_dim) select embeddings of previous nodes\n",
        "        cur_embedded_node = tf.gather(embeddings, tf.cast(prev_node, tf.int32), batch_dims=1)  # (batch_size, 1, input_dim)\n",
        "\n",
        "        # add remaining capacity\n",
        "        step_context = tf.concat([cur_embedded_node, self.problem.VEHICLE_CAPACITY - state.used_capacity[:, :, None]], axis=-1)\n",
        "\n",
        "        return step_context  # (batch_size, 1, input_dim + 1)\n",
        "\n",
        "    def decoder_mha(self, Q, K, V, mask=None):\n",
        "        \"\"\" Computes Multi-Head Attention part of decoder\n",
        "        Basically, its a part of MHA sublayer, but we cant construct a layer since Q changes in a decoding loop.\n",
        "        Args:\n",
        "            mask: a mask for visited nodes,\n",
        "                has shape (batch_size, seq_len_q, seq_len_k), seq_len_q = 1 for context vector attention in decoder\n",
        "            Q: query (context vector for decoder)\n",
        "                    has shape (..., seq_len_q, head_depth) with seq_len_q = 1 for context_vector attention in decoder\n",
        "            K, V: key, value (projections of nodes embeddings)\n",
        "                have shape (..., seq_len_k, head_depth), (..., seq_len_v, head_depth),\n",
        "                                                                with seq_len_k = seq_len_v = n_nodes for decoder\n",
        "        \"\"\"\n",
        "\n",
        "        compatibility = tf.matmul(Q, K, transpose_b=True)/tf.math.sqrt(self.dk_mha_decoder)  # (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "\n",
        "        if mask is not None:\n",
        "\n",
        "            # we need to reshape mask:\n",
        "            # (batch_size, seq_len_q, seq_len_k) --> (batch_size, 1, seq_len_q, seq_len_k)\n",
        "            # so that we will be able to do a broadcast:\n",
        "            # (batch_size, num_heads, seq_len_q, seq_len_k) + (batch_size, 1, seq_len_q, seq_len_k)\n",
        "            mask = mask[:, tf.newaxis, :, :]\n",
        "\n",
        "            # we use tf.where since 0*-np.inf returns nan, but not -np.inf\n",
        "            # compatibility = tf.where(\n",
        "            #                     tf.broadcast_to(mask, compatibility.shape), tf.ones_like(compatibility) * (-np.inf),\n",
        "            #                     compatibility\n",
        "            #                      )\n",
        "\n",
        "            compatibility = tf.where(mask,\n",
        "                                     tf.ones_like(compatibility) * (-np.inf),\n",
        "                                     compatibility\n",
        "                                     )\n",
        "\n",
        "\n",
        "        compatibility = tf.nn.softmax(compatibility, axis=-1)  # (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        attention = tf.matmul(compatibility, V)  # (batch_size, num_heads, seq_len_q, head_depth)\n",
        "\n",
        "        # transpose back to (batch_size, seq_len_q, num_heads, depth)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        # concatenate heads (last 2 dimensions)\n",
        "        attention = tf.reshape(attention, (self.batch_size, -1, self.output_dim))  # (batch_size, seq_len_q, output_dim)\n",
        "\n",
        "        output = self.w_out(attention)  # (batch_size, seq_len_q, output_dim), seq_len_q = 1 for context att in decoder\n",
        "\n",
        "        return output\n",
        "\n",
        "    def get_log_p(self, Q, K, mask=None):\n",
        "        \"\"\"Single-Head attention sublayer in decoder,\n",
        "        computes log-probabilities for node selection.\n",
        "        Args:\n",
        "            mask: mask for nodes\n",
        "            Q: query (output of mha layer)\n",
        "                    has shape (batch_size, seq_len_q, output_dim), seq_len_q = 1 for context attention in decoder\n",
        "            K: key (projection of node embeddings)\n",
        "                    has shape  (batch_size, seq_len_k, output_dim), seq_len_k = n_nodes for decoder\n",
        "        \"\"\"\n",
        "\n",
        "        compatibility = tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(self.dk_get_loc_p)\n",
        "        compatibility = tf.math.tanh(compatibility) * self.tanh_clipping\n",
        "\n",
        "        if mask is not None:\n",
        "\n",
        "            # we dont need to reshape mask like we did in multi-head version:\n",
        "            # (batch_size, seq_len_q, seq_len_k) --> (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "            # since we dont have multiple heads\n",
        "\n",
        "            # compatibility = tf.where(\n",
        "            #                     tf.broadcast_to(mask, compatibility.shape), tf.ones_like(compatibility) * (-np.inf),\n",
        "            #                     compatibility\n",
        "            #                      )\n",
        "\n",
        "            compatibility = tf.where(mask,\n",
        "                                     tf.ones_like(compatibility) * (-np.inf),\n",
        "                                     compatibility\n",
        "                                     )\n",
        "\n",
        "        log_p = tf.nn.log_softmax(compatibility, axis=-1)  # (batch_size, seq_len_q, seq_len_k)\n",
        "\n",
        "        return log_p\n",
        "\n",
        "    def get_log_likelihood(self, _log_p, a):\n",
        "\n",
        "        # Get log_p corresponding to selected actions\n",
        "        log_p = tf.gather_nd(_log_p, tf.cast(tf.expand_dims(a, axis=-1), tf.int32), batch_dims=2)\n",
        "\n",
        "        # Calculate log_likelihood\n",
        "        return tf.reduce_sum(log_p,1)\n",
        "\n",
        "    def get_projections(self, embeddings, context_vectors):\n",
        "\n",
        "        # we compute some projections (common for each policy step) before decoding loop for efficiency\n",
        "        K = self.wk(embeddings)  # (batch_size, n_nodes, output_dim)\n",
        "        K_tanh = self.wk_tanh(embeddings)  # (batch_size, n_nodes, output_dim)\n",
        "        V = self.wv(embeddings)  # (batch_size, n_nodes, output_dim)\n",
        "        Q_context = self.wq_context(context_vectors[:, tf.newaxis, :])  # (batch_size, 1, output_dim)\n",
        "\n",
        "        # we dont need to split K_tanh since there is only 1 head; Q will be split in decoding loop\n",
        "        K = self.split_heads(K, self.batch_size)  # (batch_size, num_heads, n_nodes, head_depth)\n",
        "        V = self.split_heads(V, self.batch_size)  # (batch_size, num_heads, n_nodes, head_depth)\n",
        "\n",
        "        return K_tanh, Q_context, K, V\n",
        "\n",
        "    def call(self, inputs, return_pi=False):\n",
        "\n",
        "        embeddings, mean_graph_emb = self.embedder(inputs)\n",
        "\n",
        "        self.batch_size = tf.shape(embeddings)[0]\n",
        "\n",
        "        outputs = []\n",
        "        sequences = []\n",
        "\n",
        "        state = self.problem(inputs)\n",
        "\n",
        "        K_tanh, Q_context, K, V = self.get_projections(embeddings, mean_graph_emb)\n",
        "\n",
        "        # Perform decoding steps\n",
        "        i = 0\n",
        "        inner_i = 0\n",
        "\n",
        "        while not state.all_finished():\n",
        "\n",
        "            if i > 0:\n",
        "                state.i = tf.zeros(1, dtype=tf.int64)\n",
        "                att_mask, cur_num_nodes = state.get_att_mask()\n",
        "                embeddings, context_vectors = self.embedder(inputs, att_mask, cur_num_nodes)\n",
        "                K_tanh, Q_context, K, V = self.get_projections(embeddings, context_vectors)\n",
        "\n",
        "            inner_i = 0\n",
        "            while not state.partial_finished():\n",
        "\n",
        "                step_context = self.get_step_context(state, embeddings)  # (batch_size, 1), (batch_size, 1, input_dim + 1)\n",
        "                Q_step_context = self.wq_step_context(step_context)  # (batch_size, 1, output_dim)\n",
        "                Q = Q_context + Q_step_context\n",
        "\n",
        "                # split heads for Q\n",
        "                Q = self.split_heads(Q, self.batch_size)  # (batch_size, num_heads, 1, head_depth)\n",
        "\n",
        "                # get current mask\n",
        "                mask = state.get_mask()  # (batch_size, 1, n_nodes) with True/False indicating where agent can go\n",
        "\n",
        "                # compute MHA decoder vectors for current mask\n",
        "                mha = self.decoder_mha(Q, K, V, mask)  # (batch_size, 1, output_dim)\n",
        "\n",
        "                # compute probabilities\n",
        "                log_p = self.get_log_p(mha, K_tanh, mask)  # (batch_size, 1, n_nodes)\n",
        "\n",
        "                # next step is to select node\n",
        "                selected = self._select_node(log_p)\n",
        "\n",
        "                state.step(selected)\n",
        "\n",
        "                outputs.append(log_p[:, 0, :])\n",
        "                sequences.append(selected)\n",
        "\n",
        "                inner_i += 1\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        _log_p, pi = tf.stack(outputs, 1), tf.cast(tf.stack(sequences, 1), tf.float32)\n",
        "\n",
        "        cost = self.problem.get_costs(inputs, pi)\n",
        "\n",
        "        ll = self.get_log_likelihood(_log_p, pi)\n",
        "\n",
        "        if return_pi:\n",
        "            return cost, ll, pi\n",
        "\n",
        "        return cost, ll"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B09i7W70E18X"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxILSyzCEvf7"
      },
      "source": [
        "import pickle\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "\n",
        "def create_data_on_disk(graph_size, num_samples, is_save=True, filename=None, is_return=False, seed=1234):\n",
        "    \"\"\"Generate validation dataset (with SEED) and save\n",
        "    \"\"\"\n",
        "\n",
        "    CAPACITIES = {\n",
        "        10: 20.,\n",
        "        20: 30.,\n",
        "        30: 35.,\n",
        "        40: 40.,\n",
        "        50: 45.,\n",
        "        100: 50.\n",
        "    }\n",
        "    depo, graphs, demand = (tf.random.uniform(minval=0, maxval=1, shape=(num_samples, 2), seed=seed),\n",
        "                            tf.random.uniform(minval=0, maxval=1, shape=(num_samples, graph_size, 2), seed=seed),\n",
        "                            tf.cast(tf.random.uniform(minval=1, maxval=10, shape=(num_samples, graph_size),\n",
        "                                                      dtype=tf.int32, seed=seed), tf.float32) / tf.cast(CAPACITIES[graph_size], tf.float32)\n",
        "                            )\n",
        "    if is_save:\n",
        "        save_to_pickle('Validation_dataset_{}.pkl'.format(filename), (depo, graphs, demand))\n",
        "\n",
        "    if is_return:\n",
        "        return tf.data.Dataset.from_tensor_slices((list(depo), list(graphs), list(demand)))\n",
        "\n",
        "\n",
        "def save_to_pickle(filename, item):\n",
        "    \"\"\"Save to pickle\n",
        "    \"\"\"\n",
        "    with open(filename, 'wb') as handle:\n",
        "        pickle.dump(item, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "def read_from_pickle(path, return_tf_data_set=True, num_samples=None):\n",
        "    \"\"\"Read dataset from file (pickle)\n",
        "    \"\"\"\n",
        "\n",
        "    objects = []\n",
        "    with (open(path, \"rb\")) as openfile:\n",
        "        while True:\n",
        "            try:\n",
        "                objects.append(pickle.load(openfile))\n",
        "            except EOFError:\n",
        "                break\n",
        "    objects = objects[0]\n",
        "    if return_tf_data_set:\n",
        "        depo, graphs, demand = objects\n",
        "        if num_samples is not None:\n",
        "            return tf.data.Dataset.from_tensor_slices((list(depo), list(graphs), list(demand))).take(num_samples)\n",
        "        else:\n",
        "            return tf.data.Dataset.from_tensor_slices((list(depo), list(graphs), list(demand)))\n",
        "    else:\n",
        "        return objects\n",
        "\n",
        "\n",
        "def generate_data_onfly(num_samples=10000, graph_size=20):\n",
        "    \"\"\"Generate temp dataset in memory\n",
        "    \"\"\"\n",
        "\n",
        "    CAPACITIES = {\n",
        "        10: 20.,\n",
        "        20: 30.,\n",
        "        30: 35.,\n",
        "        40: 40.,\n",
        "        50: 45.,\n",
        "        100: 50.\n",
        "    }\n",
        "    depo, graphs, demand = (tf.random.uniform(minval=0, maxval=1, shape=(num_samples, 2)),\n",
        "                            tf.random.uniform(minval=0, maxval=1, shape=(num_samples, graph_size, 2)),\n",
        "                            tf.cast(tf.random.uniform(minval=1, maxval=10, shape=(num_samples, graph_size),\n",
        "                                                      dtype=tf.int32), tf.float32)/tf.cast(CAPACITIES[graph_size], tf.float32)\n",
        "                            )\n",
        "\n",
        "    return tf.data.Dataset.from_tensor_slices((list(depo), list(graphs), list(demand)))\n",
        "\n",
        "\n",
        "def get_results(train_loss_results, train_cost_results, val_cost, save_results=True, filename=None, plots=True):\n",
        "\n",
        "    epochs_num = len(train_loss_results)\n",
        "\n",
        "    df_train = pd.DataFrame(data={'epochs': list(range(epochs_num)),\n",
        "                                  'loss': train_loss_results,\n",
        "                                  'cost': train_cost_results,\n",
        "                                  })\n",
        "    df_test = pd.DataFrame(data={'epochs': list(range(epochs_num)),\n",
        "                                 'val_сost': val_cost})\n",
        "    if save_results:\n",
        "        df_train.to_excel('train_results_{}.xlsx'.format(filename), index=False)\n",
        "        df_test.to_excel('test_results_{}.xlsx'.format(filename), index=False)\n",
        "\n",
        "    if plots:\n",
        "        plt.figure(figsize=(15, 9))\n",
        "        ax = sns.lineplot(x='epochs', y='loss', data=df_train, color='salmon', label='train loss')\n",
        "        ax2 = ax.twinx()\n",
        "        sns.lineplot(x='epochs', y='cost', data=df_train, color='cornflowerblue', label='train cost', ax=ax2)\n",
        "        sns.lineplot(x='epochs', y='val_сost', data=df_test, palette='darkblue', label='val cost').set(ylabel='cost')\n",
        "        ax.legend(loc=(0.75, 0.90), ncol=1)\n",
        "        ax2.legend(loc=(0.75, 0.95), ncol=2)\n",
        "        ax.grid(axis='x')\n",
        "        ax2.grid(True)\n",
        "        plt.savefig('learning_curve_plot_{}.jpg'.format(filename))\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def get_journey(batch, pi,GRAPH_SIZE, ind_in_batch=0):\n",
        "    \"\"\"Plots journey of agent\n",
        "    Args:\n",
        "        batch: dataset of graphs\n",
        "        pi: paths of agent obtained from model\n",
        "        ind_in_batch: index of graph in batch to be plotted\n",
        "    \"\"\"\n",
        "\n",
        "    # Remove extra zeros\n",
        "    pi_ = get_clean_path(pi[ind_in_batch].numpy())\n",
        "    CAPACITIES = {10: 20.,\n",
        "                  20: 30.,\n",
        "                  30: 35.,\n",
        "                  40: 40.,\n",
        "                  50: 45.,\n",
        "                  100: 50.\n",
        "                  }\n",
        "\n",
        "    # Unpack variables\n",
        "    depo_coord = batch[0][ind_in_batch].numpy()\n",
        "    points_coords = batch[1][ind_in_batch].numpy()\n",
        "    demands = batch[2][ind_in_batch].numpy()*CAPACITIES[GRAPH_SIZE]\n",
        "    node_labels = ['(' + str(x[0]) + ', ' + x[1] + ')' for x in enumerate(demands.round(2).astype(str))]\n",
        "\n",
        "    # Concatenate depot and points\n",
        "    full_coords = np.concatenate((depo_coord.reshape(1, 2), points_coords))\n",
        "\n",
        "    # Get list with agent loops in path\n",
        "    list_of_paths = []\n",
        "    cur_path = []\n",
        "    for idx, node in enumerate(pi_):\n",
        "\n",
        "        cur_path.append(node)\n",
        "\n",
        "        if idx != 0 and node == 0:\n",
        "            if cur_path[0] != 0:\n",
        "                cur_path.insert(0, 0)\n",
        "            list_of_paths.append(cur_path)\n",
        "            cur_path = []\n",
        "          \n",
        "    Total_distance=0\n",
        "    list_of_path_traces = []\n",
        "    for path_counter, path in enumerate(list_of_paths):\n",
        "        coords = full_coords[[int(x) for x in path]]\n",
        "\n",
        "        # Calculate length of each agent loop\n",
        "        lengths = np.sqrt(np.sum(np.diff(coords, axis=0) ** 2, axis=1))\n",
        "        total_length = np.sum(lengths)\n",
        "        Total_distance+=total_length\n",
        "\n",
        "        list_of_path_traces.append(go.Scatter(x=coords[:, 0],\n",
        "                                              y=coords[:, 1],\n",
        "                                              mode=\"markers+lines\",\n",
        "                                              name=f\"path_{path_counter+1}, length={total_length:.2f}\",\n",
        "                                              opacity=1.0))\n",
        "    Total_distance\n",
        "    trace_points = go.Scatter(x=points_coords[:, 0],\n",
        "                              y=points_coords[:, 1],\n",
        "                              mode='markers+text',\n",
        "                              name='destinations',\n",
        "                              text=node_labels,\n",
        "                              textposition='top center',\n",
        "                              marker=dict(size=7),\n",
        "                              opacity=1.0\n",
        "                              )\n",
        "\n",
        "    trace_depo = go.Scatter(x=[depo_coord[0]],\n",
        "                            y=[depo_coord[1]],\n",
        "                            text=['1.0'], textposition='bottom center',\n",
        "                            mode='markers+text',\n",
        "                            marker=dict(size=15),\n",
        "                            name='depot'\n",
        "                            )\n",
        "\n",
        "    layout = go.Layout(title='<b>{}_Customers_ML_Model_Total_Distance_{}</b>'.format(GRAPH_SIZE,round(Total_distance,2)),\n",
        "                       xaxis=dict(title='X coordinate'),\n",
        "                       yaxis=dict(title='Y coordinate'),\n",
        "                       showlegend=True,\n",
        "                       width=1000,\n",
        "                       height=1000,\n",
        "                       template=\"plotly_white\"\n",
        "                       )\n",
        "\n",
        "    data = [trace_points, trace_depo] + list_of_path_traces\n",
        "    print('Current path: ', pi_)\n",
        "    fig = go.Figure(data=data, layout=layout)\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "def get_cur_time():\n",
        "    \"\"\"Returns local time as string\n",
        "    \"\"\"\n",
        "    ts = time.time()\n",
        "    return datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "\n",
        "def get_clean_path(arr):\n",
        "    \"\"\"Returns extra zeros from path.\n",
        "       Dynamical model generates duplicated zeros for several graphs when obtaining partial solutions.\n",
        "    \"\"\"\n",
        "\n",
        "    p1, p2 = 0, 1\n",
        "    output = []\n",
        "\n",
        "    while p2 < len(arr):\n",
        "\n",
        "        if arr[p1] != arr[p2]:\n",
        "            output.append(arr[p1])\n",
        "            if p2 == len(arr) - 1:\n",
        "                output.append(arr[p2])\n",
        "\n",
        "        p1 += 1\n",
        "        p2 += 1\n",
        "\n",
        "    if output[0] != 0:\n",
        "        output.insert(0, 0.0)\n",
        "    if output[-1] != 0:\n",
        "        output.append(0.0)\n",
        "\n",
        "    return output\n",
        "\n",
        "def get_journey_savings(tour,routes, GRAPH_SIZE):\n",
        "  import plotly.graph_objects as go\n",
        "  import numpy as np\n",
        "  depot_cord=tour[0].numpy().squeeze()\n",
        "  location_values=tour[1].numpy().squeeze()\n",
        "  CAPACITIES = {10: 20.,\n",
        "                  20: 30.,\n",
        "                  30: 35.,\n",
        "                  40: 40.,\n",
        "                  50: 45.,\n",
        "                  100: 50.\n",
        "                  }\n",
        "  demand_values=tour[2][0].numpy()*CAPACITIES[GRAPH_SIZE]\n",
        "  all_coords = np.concatenate((depot_cord.reshape(1, 2), location_values))\n",
        "  node_labels = ['(' + str(x[0]) + ', ' + x[1] + ')' for x in enumerate(demand_values.round(2).astype(str))]\n",
        "  list_of_path_traces=[]\n",
        "  total_length=0\n",
        "\n",
        "  for k,v in routes.items():\n",
        "    # Calculate length of each agent loop\n",
        "    lengths = np.sum(np.sqrt(np.sum(np.diff(v, axis=0) ** 2, axis=1)))\n",
        "    total_length+=lengths\n",
        "    list_of_path_traces.append(go.Scatter(x=np.array(v)[:, 0],\n",
        "                                           y=np.array(v)[:, 1],\n",
        "                                           mode=\"markers+lines\",\n",
        "                                           name=f\"path_{k+1}, length={lengths:.2f}\",\n",
        "                                           opacity=1.0))\n",
        "\n",
        "  trace_points = go.Scatter(x=location_values[:, 0],\n",
        "                              y=location_values[:, 1],\n",
        "                              mode='markers+text',\n",
        "                              name='destinations',\n",
        "                              text=node_labels,\n",
        "                              textposition='top center',\n",
        "                              marker=dict(size=7),\n",
        "                              opacity=1.0\n",
        "                              )\n",
        "\n",
        "  depo_point = go.Scatter(x=[depot_cord[0]],\n",
        "                            y=[depot_cord[1]],\n",
        "                            text=['1.0'], textposition='bottom center',\n",
        "                            mode='markers+text',\n",
        "                            marker=dict(size=15),\n",
        "                            name='depot'\n",
        "                            )\n",
        "  layout = go.Layout(title='<b>{}_Customers_Savings_Algorithm_Total_Distance_{}</b>'.format(GRAPH_SIZE,round(total_length,2)),\n",
        "                       xaxis=dict(title='X coordinate'),\n",
        "                       yaxis=dict(title='Y coordinate'),\n",
        "                       showlegend=True,\n",
        "                       width=1000,\n",
        "                       height=1000,\n",
        "                       template=\"plotly_white\"\n",
        "                       )\n",
        "  data = [trace_points, depo_point]+ list_of_path_traces\n",
        "  fig = go.Figure(data=data, layout=layout)\n",
        "  fig.show()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCCUReXfFHRB"
      },
      "source": [
        "# Utils demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib2ZedgRFIXZ"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def f_get_results_plot_seaborn(data, title, graph_size=20):\n",
        "    fig = plt.figure(figsize=(15, 9))\n",
        "    ax = fig.add_subplot()\n",
        "    ax.plot(data['epochs'], data['train_loss'], color='salmon', label='train loss')\n",
        "    ax2 = ax.twinx()\n",
        "    ax2.plot(data['epochs'], data['train_cost'],  color='cornflowerblue', label='train cost')\n",
        "    ax2.plot(data['epochs'], data['val_cost'], color='darkblue', label='val cost')\n",
        "\n",
        "    if graph_size == 20:\n",
        "        am_val = 6.4\n",
        "    else:\n",
        "        am_val = 10.98\n",
        "\n",
        "    plt.axhline(y=am_val, color='black', linestyle='--', linewidth=1.5, label='AM article best score')\n",
        "\n",
        "    fig.legend(loc=\"upper right\", bbox_to_anchor=(1,1), bbox_transform=ax.transAxes)\n",
        "    \n",
        "    ax.set_ylabel('Loss')\n",
        "    ax2.set_ylabel('Cost')\n",
        "    ax.set_xlabel('Epochs')\n",
        "    ax.grid(False)\n",
        "    ax2.grid(False)\n",
        "    ax2.set_yticks(np.arange(min(data['val_cost'].min(), data['train_cost'].min())-0.2,\n",
        "                             max(data['val_cost'].max(), data['train_cost'].max())+0.1,\n",
        "                             0.1).round(2))\n",
        "    plt.title('Learning Curve: ' + title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def f_get_results_plot_plotly(data, title, graph_size=20):\n",
        "    # Create figure with secondary y-axis\n",
        "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "    # Add traces\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=data['epochs'], y=data['train_loss'], name=\"train loss\", marker_color='salmon'),\n",
        "        secondary_y=False,\n",
        "    )\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=data['epochs'], y=data['train_cost'], name=\"train cost\", marker_color='cornflowerblue'),\n",
        "        secondary_y=True,\n",
        "    )\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=data['epochs'], y=data['val_cost'], name=\"val cost\", marker_color='darkblue'),\n",
        "        secondary_y=True,\n",
        "    )\n",
        "\n",
        "    # Add figure title\n",
        "    fig.update_layout(\n",
        "        title_text=\"Learning Curve: \" + title,\n",
        "        width=950,\n",
        "        height=650,\n",
        "        # plot_bgcolor='rgba(0,0,0,0)'\n",
        "        template=\"plotly_white\"\n",
        "    )\n",
        "\n",
        "    # Set x-axis title\n",
        "    fig.update_xaxes(title_text=\"Number of epoch\")\n",
        "\n",
        "    # Set y-axes titles\n",
        "    fig.update_yaxes(title_text=\"<b>Loss\", secondary_y=False, showgrid=False, zeroline=False)\n",
        "    fig.update_yaxes(title_text=\"<b>Cost\", secondary_y=True, dtick=0.1)#, nticks=20)\n",
        "\n",
        "    fig.show()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlCzeKzsD4-9"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Td_31mvEpg_"
      },
      "source": [
        "import tensorflow as tf\n",
        "from scipy.stats import ttest_rel\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "#from attention_dynamic_model import AttentionDynamicModel\n",
        "#from attention_dynamic_model import set_decode_type\n",
        "#from utils import generate_data_onfly\n",
        "\n",
        "\n",
        "def copy_of_tf_model(model, embedding_dim=128, graph_size=20):\n",
        "    \"\"\"Copy model weights to new model\n",
        "    \"\"\"\n",
        "    # https://stackoverflow.com/questions/56841736/how-to-copy-a-network-in-tensorflow-2-0\n",
        "    CAPACITIES = {10: 20.,\n",
        "                  20: 30.,\n",
        "                  30: 35.,\n",
        "                  40: 40.,\n",
        "                  50: 45.,\n",
        "                  100: 50.\n",
        "                  }\n",
        "\n",
        "    data_random = [tf.random.uniform((2, 2,), minval=0, maxval=1, dtype=tf.dtypes.float32),\n",
        "                   tf.random.uniform((2, graph_size, 2), minval=0, maxval=1, dtype=tf.dtypes.float32),\n",
        "                   tf.cast(tf.random.uniform(minval=1, maxval=10, shape=(2, graph_size),\n",
        "                                             dtype=tf.int32), tf.float32) / tf.cast(CAPACITIES[graph_size], tf.float32)]\n",
        "\n",
        "    new_model = AttentionDynamicModel(embedding_dim)\n",
        "    set_decode_type(new_model, \"sampling\")\n",
        "    _, _ = new_model(data_random)\n",
        "\n",
        "    for a, b in zip(new_model.variables, model.variables):\n",
        "        a.assign(b)\n",
        "\n",
        "    return new_model\n",
        "\n",
        "def rollout(model, dataset, batch_size = 1000, disable_tqdm = False):\n",
        "    # Evaluate model in greedy mode\n",
        "    set_decode_type(model, \"greedy\")\n",
        "    costs_list = []\n",
        "\n",
        "    for batch in tqdm(dataset.batch(batch_size), disable=disable_tqdm, desc=\"Rollout greedy execution\"):\n",
        "        cost, _ = model(batch)\n",
        "        costs_list.append(cost)\n",
        "\n",
        "    return tf.concat(costs_list, axis=0)\n",
        "\n",
        "\n",
        "def validate(dataset, model, batch_size=1000):\n",
        "    \"\"\"Validates model on given dataset in greedy mode\n",
        "    \"\"\"\n",
        "    val_costs = rollout(model, dataset, batch_size=batch_size)\n",
        "    set_decode_type(model, \"sampling\")\n",
        "    mean_cost = tf.reduce_mean(val_costs)\n",
        "    print(f\"Validation score: {np.round(mean_cost, 4)}\")\n",
        "    return mean_cost\n",
        "\n",
        "\n",
        "class RolloutBaseline:\n",
        "\n",
        "    def __init__(self, model, filename,\n",
        "                 from_checkpoint=False,\n",
        "                 path_to_checkpoint=None,\n",
        "                 wp_n_epochs=1,\n",
        "                 epoch=0,\n",
        "                 num_samples=10000,\n",
        "                 warmup_exp_beta=0.8,\n",
        "                 embedding_dim=128,\n",
        "                 graph_size=20):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model: current model\n",
        "            filename: suffix for baseline checkpoint filename\n",
        "            from_checkpoint: start from checkpoint flag\n",
        "            path_to_checkpoint: path to baseline model weights\n",
        "            wp_n_epochs: number of warm-up epochs\n",
        "            epoch: current epoch number\n",
        "            num_samples: number of samples to be generated for baseline dataset\n",
        "            warmup_exp_beta: warmup mixing parameter (exp. moving average parameter)\n",
        "        \"\"\"\n",
        "\n",
        "        self.num_samples = num_samples\n",
        "        self.cur_epoch = epoch\n",
        "        self.wp_n_epochs = wp_n_epochs\n",
        "        self.beta = warmup_exp_beta\n",
        "\n",
        "        # controls the amount of warmup\n",
        "        self.alpha = 0.0\n",
        "\n",
        "        self.running_average_cost = None\n",
        "\n",
        "        # Checkpoint params\n",
        "        self.filename = filename\n",
        "        self.from_checkpoint = from_checkpoint\n",
        "        self.path_to_checkpoint = path_to_checkpoint\n",
        "\n",
        "        # Problem params\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.graph_size = graph_size\n",
        "\n",
        "        # create and evaluate initial baseline\n",
        "        self._update_baseline(model, epoch)\n",
        "\n",
        "\n",
        "    def _update_baseline(self, model, epoch):\n",
        "\n",
        "        # Load or copy baseline model based on self.from_checkpoint condition\n",
        "        if self.from_checkpoint and self.alpha == 0:\n",
        "            print('Baseline model loaded')\n",
        "            self.model = load_tf_model(self.path_to_checkpoint,\n",
        "                                       embedding_dim=self.embedding_dim,\n",
        "                                       graph_size=self.graph_size)\n",
        "        else:\n",
        "            self.model = copy_of_tf_model(model,\n",
        "                                          embedding_dim=self.embedding_dim,\n",
        "                                          graph_size=self.graph_size)\n",
        "\n",
        "            # For checkpoint\n",
        "            self.model.save_weights('baseline_checkpoint_epoch_{}.h5'.format(self.filename), save_format='h5')\n",
        "\n",
        "        # We generate a new dataset for baseline model on each baseline update to prevent possible overfitting\n",
        "        self.dataset = generate_data_onfly(num_samples=self.num_samples, graph_size=self.graph_size)\n",
        "\n",
        "        print(f\"Evaluating baseline model on baseline dataset (epoch = {epoch})\")\n",
        "        self.bl_vals = rollout(self.model, self.dataset)\n",
        "        self.mean = tf.reduce_mean(self.bl_vals)\n",
        "        self.cur_epoch = epoch\n",
        "\n",
        "    def ema_eval(self, cost):\n",
        "        \"\"\"This is running average of cost through previous batches (only for warm-up epochs)\n",
        "        \"\"\"\n",
        "\n",
        "        if self.running_average_cost is None:\n",
        "            self.running_average_cost = tf.reduce_mean(cost)\n",
        "        else:\n",
        "            self.running_average_cost = self.beta * self.running_average_cost + (1. - self.beta) * tf.reduce_mean(cost)\n",
        "\n",
        "        return self.running_average_cost\n",
        "\n",
        "    def eval(self, batch, cost):\n",
        "        \"\"\"Evaluates current baseline model on single training batch\n",
        "        \"\"\"\n",
        "\n",
        "        if self.alpha == 0:\n",
        "            return self.ema_eval(cost)\n",
        "\n",
        "        if self.alpha < 1:\n",
        "            v_ema = self.ema_eval(cost)\n",
        "        else:\n",
        "            v_ema = 0.0\n",
        "\n",
        "        v_b, _ = self.model(batch)\n",
        "\n",
        "        v_b = tf.stop_gradient(v_b)\n",
        "        v_ema = tf.stop_gradient(v_ema)\n",
        "\n",
        "        # Combination of baseline cost and exp. moving average cost\n",
        "        return self.alpha * v_b + (1 - self.alpha) * v_ema\n",
        "\n",
        "    def eval_all(self, dataset):\n",
        "        \"\"\"Evaluates current baseline model on the whole dataset only for non warm-up epochs\n",
        "        \"\"\"\n",
        "\n",
        "        if self.alpha < 1:\n",
        "            return None\n",
        "\n",
        "        val_costs = rollout(self.model, dataset, batch_size=2048)\n",
        "\n",
        "        return val_costs\n",
        "\n",
        "    def epoch_callback(self, model, epoch):\n",
        "        \"\"\"Compares current baseline model with the training model and updates baseline if it is improved\n",
        "        \"\"\"\n",
        "\n",
        "        self.cur_epoch = epoch\n",
        "\n",
        "        print(f\"Evaluating candidate model on baseline dataset (callback epoch = {self.cur_epoch})\")\n",
        "        candidate_vals = rollout(model, self.dataset)  # costs for training model on baseline dataset\n",
        "        candidate_mean = tf.reduce_mean(candidate_vals)\n",
        "\n",
        "        diff = candidate_mean - self.mean\n",
        "\n",
        "        print(f\"Epoch {self.cur_epoch} candidate mean {candidate_mean}, baseline epoch {self.cur_epoch} mean {self.mean}, difference {diff}\")\n",
        "\n",
        "        if diff < 0:\n",
        "            # statistic + p-value\n",
        "            t, p = ttest_rel(candidate_vals, self.bl_vals)\n",
        "\n",
        "            p_val = p / 2\n",
        "            print(f\"p-value: {p_val}\")\n",
        "\n",
        "            if p_val < 0.05:\n",
        "                print('Update baseline')\n",
        "                self._update_baseline(model, self.cur_epoch)\n",
        "\n",
        "        # alpha controls the amount of warmup\n",
        "        if self.alpha < 1.0:\n",
        "            self.alpha = (self.cur_epoch + 1) / float(self.wp_n_epochs)\n",
        "            print(f\"alpha was updated to {self.alpha}\")\n",
        "\n",
        "\n",
        "def load_tf_model(path, embedding_dim=128, graph_size=20, n_encode_layers=3):\n",
        "    \"\"\"Load model weights from hd5 file\n",
        "    \"\"\"\n",
        "    # https://stackoverflow.com/questions/51806852/cant-save-custom-subclassed-model\n",
        "    CAPACITIES = {10: 20.,\n",
        "                  20: 30.,\n",
        "                  30: 35.,\n",
        "                  40: 40.,\n",
        "                  50: 45.,\n",
        "                  100: 50.\n",
        "                  }\n",
        "\n",
        "    data_random = [tf.random.uniform((2, 2,), minval=0, maxval=1, dtype=tf.dtypes.float32),\n",
        "                   tf.random.uniform((2, graph_size, 2), minval=0, maxval=1, dtype=tf.dtypes.float32),\n",
        "                   tf.cast(tf.random.uniform(minval=1, maxval=10, shape=(2, graph_size),\n",
        "                                             dtype=tf.int32), tf.float32) / tf.cast(CAPACITIES[graph_size], tf.float32)]\n",
        "\n",
        "    model_loaded = AttentionDynamicModel(embedding_dim,n_encode_layers=n_encode_layers)\n",
        "    set_decode_type(model_loaded, \"greedy\")\n",
        "    _, _ = model_loaded(data_random)\n",
        "\n",
        "    model_loaded.load_weights(path)\n",
        "\n",
        "    return model_loaded"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zcYfiSCFecH"
      },
      "source": [
        "# train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKM22PjiFdS2"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "#from attention_dynamic_model import set_decode_type\n",
        "#from reinforce_baseline import validate\n",
        "\n",
        "#from utils import generate_data_onfly, get_results, get_cur_time\n",
        "#from time import gmtime, strftime\n",
        "\n",
        "\n",
        "def train_model(optimizer,\n",
        "                model_tf,\n",
        "                baseline,\n",
        "                validation_dataset,\n",
        "                samples = 1280000,\n",
        "                batch = 128,\n",
        "                val_batch_size = 1000,\n",
        "                start_epoch = 0,\n",
        "                end_epoch = 5,\n",
        "                from_checkpoint = False,\n",
        "                grad_norm_clipping = 1.0,\n",
        "                batch_verbose = 1000,\n",
        "                graph_size = 20,\n",
        "                filename = None\n",
        "                ):\n",
        "\n",
        "    if filename is None:\n",
        "        filename = 'VRP_{}'.format(graph_size)\n",
        "\n",
        "    def rein_loss(model, inputs, baseline, num_batch):\n",
        "        \"\"\"Calculate loss for REINFORCE algorithm\n",
        "        \"\"\"\n",
        "\n",
        "        # Evaluate model, get costs and log probabilities\n",
        "        cost, log_likelihood = model(inputs)\n",
        "\n",
        "        # Evaluate baseline\n",
        "        # For first wp_n_epochs we take the combination of baseline and ema for previous batches\n",
        "        # after that we take a slice of precomputed baseline values\n",
        "        bl_val = bl_vals[num_batch] if bl_vals is not None else baseline.eval(inputs, cost)\n",
        "        bl_val = tf.stop_gradient(bl_val)\n",
        "\n",
        "        # Calculate loss\n",
        "        reinforce_loss = tf.reduce_mean((cost - bl_val) * log_likelihood)\n",
        "\n",
        "        return reinforce_loss, tf.reduce_mean(cost)\n",
        "\n",
        "    def grad(model, inputs, baseline, num_batch):\n",
        "        \"\"\"Calculate gradients\n",
        "        \"\"\"\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss, cost = rein_loss(model, inputs, baseline, num_batch)\n",
        "        return loss, cost, tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    # For plotting\n",
        "    train_loss_results = []\n",
        "    train_cost_results = []\n",
        "    val_cost_avg = []\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(start_epoch, end_epoch):\n",
        "\n",
        "        # Create dataset on current epoch\n",
        "        data = generate_data_onfly(num_samples=samples, graph_size=graph_size)\n",
        "\n",
        "        epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "        epoch_cost_avg = tf.keras.metrics.Mean()\n",
        "\n",
        "        # Skip warm-up stage when we continue training from checkpoint\n",
        "        if from_checkpoint and baseline.alpha != 1.0:\n",
        "            print('Skipping warm-up mode')\n",
        "            baseline.alpha = 1.0\n",
        "\n",
        "        # If epoch > wp_n_epochs then precompute baseline values for the whole dataset else None\n",
        "        bl_vals = baseline.eval_all(data)  # (samples, ) or None\n",
        "        bl_vals = tf.reshape(bl_vals, (-1, batch)) if bl_vals is not None else None # (n_batches, batch) or None\n",
        "\n",
        "        print(\"Current decode type: {}\".format(model_tf.decode_type))\n",
        "\n",
        "        for num_batch, x_batch in tqdm(enumerate(data.batch(batch)), desc=\"batch calculation at epoch {}\".format(epoch)):\n",
        "\n",
        "            # Optimize the model\n",
        "            loss_value, cost_val, grads = grad(model_tf, x_batch, baseline, num_batch)\n",
        "\n",
        "            # Clip gradients by grad_norm_clipping\n",
        "            init_global_norm = tf.linalg.global_norm(grads)\n",
        "            grads, _ = tf.clip_by_global_norm(grads, grad_norm_clipping)\n",
        "            global_norm = tf.linalg.global_norm(grads)\n",
        "\n",
        "            if num_batch%batch_verbose == 0:\n",
        "                print(\"grad_global_norm = {}, clipped_norm = {}\".format(init_global_norm.numpy(), global_norm.numpy()))\n",
        "\n",
        "            optimizer.apply_gradients(zip(grads, model_tf.trainable_variables))\n",
        "\n",
        "            # Track progress\n",
        "            epoch_loss_avg.update_state(loss_value)\n",
        "            epoch_cost_avg.update_state(cost_val)\n",
        "\n",
        "            if num_batch%batch_verbose == 0:\n",
        "                print(\"Epoch {} (batch = {}): Loss: {}: Cost: {}\".format(epoch, num_batch, epoch_loss_avg.result(), epoch_cost_avg.result()))\n",
        "\n",
        "        # Update baseline if the candidate model is good enough. In this case also create new baseline dataset\n",
        "        baseline.epoch_callback(model_tf, epoch)\n",
        "        set_decode_type(model_tf, \"sampling\")\n",
        "\n",
        "        # Save model weights\n",
        "        model_tf.save_weights('model_checkpoint_epoch_{}.h5'.format(filename), save_format='h5')\n",
        "\n",
        "        # Validate current model\n",
        "        val_cost = validate(validation_dataset, model_tf, val_batch_size)\n",
        "        val_cost_avg.append(val_cost)\n",
        "\n",
        "        train_loss_results.append(epoch_loss_avg.result())\n",
        "        train_cost_results.append(epoch_cost_avg.result())\n",
        "\n",
        "        pd.DataFrame(data={'epochs': list(range(start_epoch, epoch+1)),\n",
        "                           'train_loss': [x.numpy() for x in train_loss_results],\n",
        "                           'train_cost': [x.numpy() for x in train_cost_results],\n",
        "                           'val_cost': [x.numpy() for x in val_cost_avg]\n",
        "                           }).to_csv('backup_results_' + filename + '.csv', index=False)\n",
        "\n",
        "        print(get_cur_time(), \"Epoch {}: Loss: {}: Cost: {}\".format(epoch, epoch_loss_avg.result(), epoch_cost_avg.result()))\n",
        "\n",
        "    # Make plots and save results\n",
        "    filename_for_results = filename + '_start={}, end={}'.format(start_epoch, end_epoch)\n",
        "    get_results([x.numpy() for x in train_loss_results],\n",
        "                [x.numpy() for x in train_cost_results],\n",
        "                [x.numpy() for x in val_cost_avg],\n",
        "                save_results=True,\n",
        "                filename=filename_for_results,\n",
        "                plots=True)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAtwF2A27TfA"
      },
      "source": [
        "# Savings Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsA4wpKX7Ryr"
      },
      "source": [
        "def savingsalgoritm(demand_input):\n",
        "  import operator\n",
        "  from audioop import reverse\n",
        "  from ortools.constraint_solver._pywrapcp import new_BaseLns\n",
        "  from itertools import repeat\n",
        "  import math\n",
        "\n",
        "  def manhattanDistance( xy1, xy2 ):\n",
        "    \"Returns the Manhattan distance between points xy1 and xy2\"\n",
        "    return abs( xy1[0] - xy2[0] ) + abs( xy1[1] - xy2[1] )\n",
        "\n",
        "  def euclideanDistance( xy1, xy2 ):\n",
        "    \"Returns the Euclidean distance between points xy1 and xy2\"\n",
        "    return  math.sqrt(( xy2[0] - xy1[0] )**2 + ( xy2[1] - xy1[1] )**2)\n",
        "\n",
        "  def calculateRouteCost(r):\n",
        "      total = 0\n",
        "      for i in range(len(r) - 1):\n",
        "          total+= euclideanDistance(r[i] , r[i+1])\n",
        "      return total\n",
        "\n",
        "  def addDepotAtEnds(depot,route):\n",
        "      route.insert(0,depot)\n",
        "      route.append(depot)\n",
        "\n",
        "  import pandas as pd\n",
        "  data=demand_input\n",
        "  noOfCustomers = len(data['nodes'])\n",
        "  customerPosDemand = {}\n",
        "  vehicleCap = data['vehicleCapacity'][0]['1']\n",
        "  #print(vehicleCap)\n",
        "  for i in range(noOfCustomers):\n",
        "      customerPosDemand[data['nodes'][i]['x'],data['nodes'][i]['y']] = data['nodes'][i]['demand']\n",
        "\n",
        "#compute Savings for depot and i,j where i <> j\n",
        "  def computeSaving(depot, i,j):\n",
        "      iDepot = manhattanDistance(i, depot)\n",
        "      jDepot = manhattanDistance(depot, j)\n",
        "      ijDist = manhattanDistance(i, j)\n",
        "      return (iDepot + jDepot - ijDist)\n",
        "    \n",
        "  #def distDepot\n",
        "\n",
        "\n",
        "  #calculating savingss for all pairs\n",
        "  savings = {}\n",
        "  customerPositions =  list(customerPosDemand)\n",
        "  pointsLen = len(customerPositions)\n",
        "  depot = (data['depot']['x'],data['depot']['y'])\n",
        "\n",
        "\n",
        "  def allCustomersConsidered(customerServed):\n",
        "      for val in customerServed.values():\n",
        "          if val == False:\n",
        "              return False\n",
        "      return True\n",
        "\n",
        "  #Step 1\n",
        "  distanceDict = {}\n",
        "  for i in range(pointsLen):\n",
        "      for j in range(i+1,pointsLen):\n",
        "          distanceDict[(customerPositions[i], customerPositions[j])] = euclideanDistance(customerPositions[i], customerPositions[j])\n",
        "  #print(distanceDict)\n",
        "  #Step 2\n",
        "  for i in range(pointsLen):\n",
        "      for j in range(i+1,pointsLen):\n",
        "          savings[customerPositions[i], customerPositions[j]]  =  computeSaving(depot,customerPositions[i], customerPositions[j])\n",
        "  savings = sorted(savings.items(),key=operator.itemgetter(1),reverse=True)\n",
        "\n",
        "  l = len(savings)\n",
        "  cust_pairs = list()\n",
        "  for i in range(l):\n",
        "      cust_pairs.append(savings[i][0])\n",
        "\n",
        "#initially none of the customers have been isServed\n",
        "  customerServed = {}\n",
        "  for c in customerPositions:\n",
        "      customerServed[c] = False\n",
        "  l = len(savings)\n",
        "  cust_pairs = list()\n",
        "  for i in range(l):\n",
        "      cust_pairs.append(savings[i][0])\n",
        "\n",
        "  #initially none of the customers have been isServed\n",
        "  customerServed = {}\n",
        "  for c in customerPositions:\n",
        "      customerServed[c] = False\n",
        "    \n",
        "  #Step 3\n",
        "  def inPrevious(new,existing):\n",
        "      start = existing[0]\n",
        "      end = existing[len(existing)-1]\n",
        "      if new == start:\n",
        "          return 1\n",
        "      elif new == end:\n",
        "          return 0\n",
        "      else:\n",
        "          return -1\n",
        "\n",
        "  def capacityValid(existing,new):\n",
        "      totalCap = customerPosDemand[new]\n",
        "      for c in existing:\n",
        "          totalCap+=customerPosDemand[c]\n",
        "\n",
        "      return totalCap <= vehicleCap\n",
        "\n",
        "  def isServed(c):\n",
        "      return customerServed[c]\n",
        "\n",
        "  def hasBeenServed(c):\n",
        "      customerServed[c] = True             \n",
        "     \n",
        "  routes = {}\n",
        "  l = len(cust_pairs)\n",
        "  i = 0\n",
        "  idx = -1\n",
        "  truck = [0,0,0,0,0,0,0]\n",
        "\n",
        "  while (not(allCustomersConsidered(customerServed))):\n",
        "      #choosing the maximum savings customers who are unserved\n",
        "      for c in cust_pairs:\n",
        "          if (isServed(c[0]) == False and isServed(c[1]) == False):\n",
        "              hasBeenServed(c[0])\n",
        "              hasBeenServed(c[1])\n",
        "              idx += 1\n",
        "              routes[idx] = ([c[0],c[1]]) \n",
        "              break\n",
        "     #finding a cust that is either at the start or end of previous route\n",
        "      for c in cust_pairs:\n",
        "          res = inPrevious(c[0], routes[idx])\n",
        "          if res == 0 and capacityValid(routes[idx], c[1]) and (isServed(c[1]) == False):\n",
        "              if c[1] == (13,7):\n",
        "                  print(customerServed[c[1]])\n",
        "              hasBeenServed(c[1])\n",
        "              routes[idx].append(c[1]) \n",
        "          elif res == 1 and capacityValid(routes[idx], c[1]) and (isServed(c[1]) == False):\n",
        "              if c[1] == (13,7):\n",
        "                  print(customerServed[c[1]])\n",
        "              hasBeenServed(c[1])\n",
        "              routes[idx].insert(0,c[1])\n",
        "        \n",
        "          else:\n",
        "              res = inPrevious(c[1], routes[idx])\n",
        "              if res == 0 and capacityValid(routes[idx], c[0]) and (isServed(c[0]) == False):\n",
        "                  if c[0] == (13,7):\n",
        "                      print(customerServed[c[0]])\n",
        "                  hasBeenServed(c[0])\n",
        "                  routes[idx].append(c[0]) \n",
        "              elif res == 1 and capacityValid(routes[idx], c[0]) and (isServed(c[0]) == False):\n",
        "                  if c[0] == (13,7):\n",
        "                      print(customerServed[c[0]])\n",
        "                  hasBeenServed(c[0])\n",
        "                  routes[idx].insert(0,c[0])\n",
        "\n",
        "# printing each truck load\n",
        "  for r in routes.values():\n",
        "      cap = 0\n",
        "      for points in r:\n",
        "          cap += customerPosDemand[points]\n",
        "   #   print('Total Capacity used:',cap)\n",
        "\n",
        "  #print(\"--------------\")\n",
        "    \n",
        "  #adding depot at ends\n",
        "  for r in routes.values():\n",
        "      addDepotAtEnds(depot, r)\n",
        "  totalDist = 0\n",
        "  for k,v in routes.items():\n",
        "      totalDist += calculateRouteCost(v)\n",
        "  totalDist\n",
        "    #  print( 'Truck:', k+1,'Distance travelled',v,round(calculateRouteCost(v),2))\n",
        "  #print(\"--------------\")\n",
        "  #print('The total distance travelled by Trucks',totalDist)\n",
        "  return routes,totalDist\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXbBRayOCp0p"
      },
      "source": [
        "# Converting the input data from the \n",
        "def savingsinput(tour):\n",
        "  import numpy as np\n",
        "  depot_cord=tour[0].numpy().squeeze()\n",
        "  location_values=tour[1].numpy().squeeze()\n",
        "  CAPACITIES = {10: 20.,\n",
        "              20: 30.,\n",
        "              30: 35.,\n",
        "              40: 40.,\n",
        "              50: 45.,\n",
        "              100: 50.}\n",
        "\n",
        "  demand_values=tour[2][0].numpy()*CAPACITIES[GRAPH_SIZE]\n",
        "  all_coords = np.concatenate((depot_cord.reshape(1, 2), location_values))\n",
        "  #Change Capacities here accordingly\n",
        "  cap = {\n",
        "        10: [{'1':20},{'2':20},{'3':20},{'4':20},{'5':20},{'6':20},{'7':20}],\n",
        "        20: [{'1':30},{'2':30},{'3':30},{'4':30},{'5':30},{'6':30},{'7':30}],\n",
        "        30: [{'1':35},{'2':35},{'3':35},{'4':35},{'5':35},{'6':35},{'7':35}],\n",
        "        40: [{'1':40},{'2':40},{'3':40},{'4':40},{'5':40},{'6':40},{'7':40}],\n",
        "        50: [{'1':45},{'2':45},{'3':45},{'4':45},{'5':45},{'6':45},{'7':45}],\n",
        "        100:[{'1':50},{'2':50},{'3':50},{'4':50},{'5':50},{'6':50},{'7':50}]}\n",
        "\n",
        "  node=[]\n",
        "  for i in range(len(demand_values)):\n",
        "    temp_dict={}\n",
        "    temp_dict['x']=location_values[i][0]#X coordiate\n",
        "    temp_dict['y']=location_values[i][1]#Y- Coordinate\n",
        "    temp_dict['demand']=np.round(demand_values[i])\n",
        "    node.append(temp_dict)\n",
        "  demand_input={'vehicleCapacity': cap[GRAPH_SIZE],'depot':{'x':depot_cord[0],'y':depot_cord[1]},'nodes':node}\n",
        "  return demand_input"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbjhNAjaFmf9"
      },
      "source": [
        "#Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prEVx5sj8T2G"
      },
      "source": [
        "Skip modelling part if you are planning to directly load the trained models without retraining the models again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo-k-bfA7f3K"
      },
      "source": [
        "#Parameters\n",
        "SAMPLES = 512 # 128*10000\n",
        "BATCH = 128\n",
        "FROM_CHECKPOINT = False\n",
        "embedding_dim = 128\n",
        "LEARNING_RATE = 0.00001\n",
        "ROLLOUT_SAMPLES = 10000\n",
        "NUMBER_OF_WP_EPOCHS = 1\n",
        "GRAD_NORM_CLIPPING = 1.0\n",
        "BATCH_VERBOSE = 1000\n",
        "VAL_BATCH_SIZE = 1000\n",
        "VALIDATE_SET_SIZE = 10000\n",
        "SEED = 1234\n",
        "print('Choose your graph size from 20 30 40 50')\n",
        "GRAPH_SIZE=int(input())\n",
        "FILENAME = 'VRP_{}'.format(GRAPH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNz6uLuTtgIH"
      },
      "source": [
        "#Epochs\n",
        "START_EPOCH = 0\n",
        "END_EPOCH = 50\n",
        "\n",
        "# Initialize model\n",
        "model_tf = AttentionDynamicModel(embedding_dim)\n",
        "set_decode_type(model_tf, \"sampling\")\n",
        "print('model initialized')\n",
        "\n",
        "# Create and save validation dataset\n",
        "validation_dataset = create_data_on_disk(GRAPH_SIZE,\n",
        "                                         VALIDATE_SET_SIZE,\n",
        "                                         is_save=True,\n",
        "                                         filename='sample',\n",
        "                                         is_return=True,\n",
        "                                         seed = SEED)\n",
        "print('validation dataset created and saved on the disk')\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
        "\n",
        "# Initialize baseline\n",
        "baseline = RolloutBaseline(model_tf,\n",
        "                           wp_n_epochs = NUMBER_OF_WP_EPOCHS,\n",
        "                           epoch = 0,\n",
        "                           num_samples=ROLLOUT_SAMPLES,\n",
        "                           filename = FILENAME,\n",
        "                           from_checkpoint = FROM_CHECKPOINT,\n",
        "                           embedding_dim=embedding_dim,\n",
        "                           graph_size=GRAPH_SIZE\n",
        "                           )\n",
        "print('baseline initialized')\n",
        "\n",
        "train_model(optimizer,\n",
        "            model_tf,\n",
        "            baseline,\n",
        "            validation_dataset,\n",
        "            samples = SAMPLES,\n",
        "            batch = BATCH,\n",
        "            val_batch_size = VAL_BATCH_SIZE,\n",
        "            start_epoch = START_EPOCH,\n",
        "            end_epoch = END_EPOCH,\n",
        "            from_checkpoint = FROM_CHECKPOINT,\n",
        "            grad_norm_clipping = GRAD_NORM_CLIPPING,\n",
        "            batch_verbose = BATCH_VERBOSE,\n",
        "            graph_size = GRAPH_SIZE,\n",
        "            filename = FILENAME\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSkGrVjamDNu"
      },
      "source": [
        "# Epochs\n",
        "START_EPOCH = 50\n",
        "END_EPOCH = 100\n",
        "\n",
        "FROM_CHECKPOINT = True\n",
        "\n",
        "# Loading the models from previous epochs\n",
        "MODEL_PATH = 'model_checkpoint_VRP_{}.h5'.format(GRAPH_SIZE)\n",
        "VAL_SET_PATH = 'Validation_dataset_sample.pkl'\n",
        "BASELINE_MODEL_PATH = 'baseline_checkpoint_VRP_{}.h5'.format(GRAPH_SIZE)\n",
        "\n",
        "# Initialize model\n",
        "model_tf = load_tf_model(MODEL_PATH,\n",
        "                         embedding_dim=embedding_dim,\n",
        "                         graph_size=GRAPH_SIZE)\n",
        "set_decode_type(model_tf, \"sampling\")\n",
        "print(get_cur_time(), 'model loaded')\n",
        "\n",
        "# Create and save validation dataset\n",
        "validation_dataset = read_from_pickle(VAL_SET_PATH)\n",
        "print(get_cur_time(), 'validation dataset loaded')\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
        "\n",
        "# Initialize baseline\n",
        "baseline = RolloutBaseline(model_tf,\n",
        "                           wp_n_epochs = NUMBER_OF_WP_EPOCHS,\n",
        "                           epoch = START_EPOCH,\n",
        "                           num_samples=ROLLOUT_SAMPLES,\n",
        "                           filename = FILENAME,\n",
        "                           from_checkpoint = FROM_CHECKPOINT,\n",
        "                           embedding_dim=embedding_dim,\n",
        "                           graph_size=GRAPH_SIZE,\n",
        "                           path_to_checkpoint = BASELINE_MODEL_PATH)\n",
        "print(get_cur_time(), 'baseline initialized')\n",
        "\n",
        "train_model(optimizer,\n",
        "            model_tf,\n",
        "            baseline,\n",
        "            validation_dataset,\n",
        "            samples = SAMPLES,\n",
        "            batch = BATCH,\n",
        "            val_batch_size = VAL_BATCH_SIZE,\n",
        "            start_epoch = START_EPOCH,\n",
        "            end_epoch = END_EPOCH,\n",
        "            from_checkpoint = FROM_CHECKPOINT,\n",
        "            grad_norm_clipping = GRAD_NORM_CLIPPING,\n",
        "            batch_verbose = BATCH_VERBOSE,\n",
        "            graph_size = GRAPH_SIZE,\n",
        "            filename = FILENAME\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f0yiW6R_4K-"
      },
      "source": [
        "# Loading Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "POChC0U_Wch9",
        "outputId": "ec262761-6970-4017-84bc-5c41140f237c"
      },
      "source": [
        "# To upload the files directly\n",
        "'''\n",
        "from google.colab import files\n",
        "files.upload()'''"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom google.colab import files\\nfiles.upload()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRtAra7vkcmd",
        "outputId": "bd8fbece-433c-4f5c-bcdd-c4bd50178779"
      },
      "source": [
        "# To select customer node size\n",
        "print('Choose your graph size from 20 30 40 50')\n",
        "GRAPH_SIZE=int(input())"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Choose your graph size from 20 30 40 50\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-u1ss6exUKK"
      },
      "source": [
        "# To generate radom dataset. Uncomment this cell if you are planning to generate random data directly\n",
        "\n",
        "VALIDATE_SET_SIZE = 10000\n",
        "validation_dataset = create_data_on_disk(GRAPH_SIZE,\n",
        "                                         VALIDATE_SET_SIZE,\n",
        "                                         is_save=True,\n",
        "                                         filename='sample',\n",
        "                                         is_return=True,\n",
        "                                         seed = 121 ) \n",
        "                                        \n",
        "                                    "
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kjZnR9L5l2V"
      },
      "source": [
        "val_set_path = 'Validation_dataset_sample.pkl'\n",
        "validation_dataset = read_from_pickle(val_set_path)\n",
        "tour = [x for x in validation_dataset.batch(1)][0]\n"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HfVZuNLDI3AP",
        "outputId": "c6ae65e4-ac22-4401-fca9-2237e4186417"
      },
      "source": [
        "model_path = 'VRP_{}.h5'.format(GRAPH_SIZE)\n",
        "#Use VRP_50 if the graph size is more than 50\n",
        "#model_path = 'VRP_50.h5'\n",
        "model = load_tf_model(model_path)\n",
        "cost, ll, pi = model(tour, return_pi=True)\n",
        "print('Current cost: ', round(cost.numpy()[0],2))\n",
        "get_journey(tour, pi, GRAPH_SIZE)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current cost:  6.15\n",
            "Current path:  [0.0, 8.0, 5.0, 17.0, 6.0, 20.0, 4.0, 7.0, 15.0, 2.0, 0.0, 16.0, 19.0, 14.0, 11.0, 9.0, 18.0, 10.0, 0.0, 12.0, 13.0, 3.0, 1.0, 0.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"8596ffc8-47b4-4d1b-803e-79c06fead455\" class=\"plotly-graph-div\" style=\"height:1000px; width:1000px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"8596ffc8-47b4-4d1b-803e-79c06fead455\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '8596ffc8-47b4-4d1b-803e-79c06fead455',\n",
              "                        [{\"marker\": {\"size\": 7}, \"mode\": \"markers+text\", \"name\": \"destinations\", \"opacity\": 1.0, \"text\": [\"(0, 7.0)\", \"(1, 4.0)\", \"(2, 1.0)\", \"(3, 1.0)\", \"(4, 1.0)\", \"(5, 4.0)\", \"(6, 2.0)\", \"(7, 6.0)\", \"(8, 6.0)\", \"(9, 1.0)\", \"(10, 3.0)\", \"(11, 4.0)\", \"(12, 3.0)\", \"(13, 3.0)\", \"(14, 2.0)\", \"(15, 9.0)\", \"(16, 6.0)\", \"(17, 2.0)\", \"(18, 5.0)\", \"(19, 2.0)\"], \"textposition\": \"top center\", \"type\": \"scatter\", \"x\": [0.23867690563201904, 0.8277918100357056, 0.5040267705917358, 0.38377463817596436, 0.8153152465820312, 0.5056259632110596, 0.6257674694061279, 0.960370659828186, 0.22372961044311523, 0.09763145446777344, 0.386671781539917, 0.7048859596252441, 0.5814241170883179, 0.5660815238952637, 0.8155131340026855, 0.8163713216781616, 0.7265139818191528, 0.16919922828674316, 0.7664213180541992, 0.09463763236999512], \"y\": [0.49038589000701904, 0.5668379068374634, 0.1962757110595703, 0.8160598278045654, 0.6872965097427368, 0.9972620010375977, 0.6751703023910522, 0.5884261131286621, 0.5194656848907471, 0.03791046142578125, 0.5549148321151733, 0.24850571155548096, 0.04588925838470459, 0.48163700103759766, 0.5740116834640503, 0.5604912042617798, 0.9685283899307251, 0.12871980667114258, 0.5214728116989136, 0.9991869926452637]}, {\"marker\": {\"size\": 15}, \"mode\": \"markers+text\", \"name\": \"depot\", \"text\": [\"1.0\"], \"textposition\": \"bottom center\", \"type\": \"scatter\", \"x\": [0.5210490226745605], \"y\": [0.4113115072250366]}, {\"mode\": \"markers+lines\", \"name\": \"path_1, length=2.77\", \"opacity\": 1.0, \"type\": \"scatter\", \"x\": [0.5210490226745605, 0.960370659828186, 0.8153152465820312, 0.7265139818191528, 0.5056259632110596, 0.09463763236999512, 0.38377463817596436, 0.6257674694061279, 0.8155131340026855, 0.8277918100357056, 0.5210490226745605], \"y\": [0.4113115072250366, 0.5884261131286621, 0.6872965097427368, 0.9685283899307251, 0.9972620010375977, 0.9991869926452637, 0.8160598278045654, 0.6751703023910522, 0.5740116834640503, 0.5668379068374634, 0.4113115072250366]}, {\"mode\": \"markers+lines\", \"name\": \"path_2, length=2.03\", \"opacity\": 1.0, \"type\": \"scatter\", \"x\": [0.5210490226745605, 0.8163713216781616, 0.7664213180541992, 0.5660815238952637, 0.386671781539917, 0.22372961044311523, 0.16919922828674316, 0.09763145446777344, 0.5210490226745605], \"y\": [0.4113115072250366, 0.5604912042617798, 0.5214728116989136, 0.48163700103759766, 0.5549148321151733, 0.5194656848907471, 0.12871980667114258, 0.03791046142578125, 0.4113115072250366]}, {\"mode\": \"markers+lines\", \"name\": \"path_3, length=1.34\", \"opacity\": 1.0, \"type\": \"scatter\", \"x\": [0.5210490226745605, 0.7048859596252441, 0.5814241170883179, 0.5040267705917358, 0.23867690563201904, 0.5210490226745605], \"y\": [0.4113115072250366, 0.24850571155548096, 0.04588925838470459, 0.1962757110595703, 0.49038589000701904, 0.4113115072250366]}],\n",
              "                        {\"height\": 1000, \"showlegend\": true, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"white\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"white\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"#C8D4E3\", \"linecolor\": \"#C8D4E3\", \"minorgridcolor\": \"#C8D4E3\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"#C8D4E3\", \"linecolor\": \"#C8D4E3\", \"minorgridcolor\": \"#C8D4E3\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"white\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"#C8D4E3\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"white\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\"}, \"bgcolor\": \"white\", \"radialaxis\": {\"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}, \"yaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}, \"zaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}, \"bgcolor\": \"white\", \"caxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#EBF0F8\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#EBF0F8\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"<b>20_Customers_ML_Model_Total_Distance_6.15</b>\"}, \"width\": 1000, \"xaxis\": {\"title\": {\"text\": \"X coordinate\"}}, \"yaxis\": {\"title\": {\"text\": \"Y coordinate\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8596ffc8-47b4-4d1b-803e-79c06fead455');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AfEpQ9KLGl2"
      },
      "source": [
        "# Saving Algorithm ORtools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AHOuveTu7BX2",
        "outputId": "d264661b-cdce-4903-ad61-a15b3885d15d"
      },
      "source": [
        "# Converting the demand from Reinforcemet model\n",
        "demand_input=savingsinput(tour)\n",
        "# Computing the optimal route using Savings Algorithm\n",
        "routes,dist=savingsalgoritm(demand_input)\n",
        "#print('Routes Assigned', routes)\n",
        "print('Total distance travelled',round(dist,2))\n",
        "#Diagram\n",
        "get_journey_savings(tour,routes, GRAPH_SIZE)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total distance travelled 6.81\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"1b9db072-2f79-4089-a351-540b43eb9436\" class=\"plotly-graph-div\" style=\"height:1000px; width:1000px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"1b9db072-2f79-4089-a351-540b43eb9436\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '1b9db072-2f79-4089-a351-540b43eb9436',\n",
              "                        [{\"marker\": {\"size\": 7}, \"mode\": \"markers+text\", \"name\": \"destinations\", \"opacity\": 1.0, \"text\": [\"(0, 7.0)\", \"(1, 4.0)\", \"(2, 1.0)\", \"(3, 1.0)\", \"(4, 1.0)\", \"(5, 4.0)\", \"(6, 2.0)\", \"(7, 6.0)\", \"(8, 6.0)\", \"(9, 1.0)\", \"(10, 3.0)\", \"(11, 4.0)\", \"(12, 3.0)\", \"(13, 3.0)\", \"(14, 2.0)\", \"(15, 9.0)\", \"(16, 6.0)\", \"(17, 2.0)\", \"(18, 5.0)\", \"(19, 2.0)\"], \"textposition\": \"top center\", \"type\": \"scatter\", \"x\": [0.23867690563201904, 0.8277918100357056, 0.5040267705917358, 0.38377463817596436, 0.8153152465820312, 0.5056259632110596, 0.6257674694061279, 0.960370659828186, 0.22372961044311523, 0.09763145446777344, 0.386671781539917, 0.7048859596252441, 0.5814241170883179, 0.5660815238952637, 0.8155131340026855, 0.8163713216781616, 0.7265139818191528, 0.16919922828674316, 0.7664213180541992, 0.09463763236999512], \"y\": [0.49038589000701904, 0.5668379068374634, 0.1962757110595703, 0.8160598278045654, 0.6872965097427368, 0.9972620010375977, 0.6751703023910522, 0.5884261131286621, 0.5194656848907471, 0.03791046142578125, 0.5549148321151733, 0.24850571155548096, 0.04588925838470459, 0.48163700103759766, 0.5740116834640503, 0.5604912042617798, 0.9685283899307251, 0.12871980667114258, 0.5214728116989136, 0.9991869926452637]}, {\"marker\": {\"size\": 15}, \"mode\": \"markers+text\", \"name\": \"depot\", \"text\": [\"1.0\"], \"textposition\": \"bottom center\", \"type\": \"scatter\", \"x\": [0.5210490226745605], \"y\": [0.4113115072250366]}, {\"mode\": \"markers+lines\", \"name\": \"path_1, length=3.73\", \"opacity\": 1.0, \"type\": \"scatter\", \"x\": [0.5210490226745605, 0.38377463817596436, 0.23867690563201904, 0.22372961044311523, 0.09463763236999512, 0.09763145446777344, 0.16919922828674316, 0.5814241170883179, 0.7048859596252441, 0.8277918100357056, 0.5210490226745605], \"y\": [0.4113115072250366, 0.8160598278045654, 0.49038589000701904, 0.5194656848907471, 0.9991869926452637, 0.03791046142578125, 0.12871980667114258, 0.04588925838470459, 0.24850571155548096, 0.5668379068374634, 0.4113115072250366]}, {\"mode\": \"markers+lines\", \"name\": \"path_2, length=1.81\", \"opacity\": 1.0, \"type\": \"scatter\", \"x\": [0.5210490226745605, 0.6257674694061279, 0.5056259632110596, 0.7265139818191528, 0.8153152465820312, 0.960370659828186, 0.8155131340026855, 0.8163713216781616, 0.5210490226745605], \"y\": [0.4113115072250366, 0.6751703023910522, 0.9972620010375977, 0.9685283899307251, 0.6872965097427368, 0.5884261131286621, 0.5740116834640503, 0.5604912042617798, 0.4113115072250366]}, {\"mode\": \"markers+lines\", \"name\": \"path_3, length=1.26\", \"opacity\": 1.0, \"type\": \"scatter\", \"x\": [0.5210490226745605, 0.5660815238952637, 0.7664213180541992, 0.386671781539917, 0.5040267705917358, 0.5210490226745605], \"y\": [0.4113115072250366, 0.48163700103759766, 0.5214728116989136, 0.5549148321151733, 0.1962757110595703, 0.4113115072250366]}],\n",
              "                        {\"height\": 1000, \"showlegend\": true, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"white\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"white\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"#C8D4E3\", \"linecolor\": \"#C8D4E3\", \"minorgridcolor\": \"#C8D4E3\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"#C8D4E3\", \"linecolor\": \"#C8D4E3\", \"minorgridcolor\": \"#C8D4E3\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"white\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"#C8D4E3\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"white\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\"}, \"bgcolor\": \"white\", \"radialaxis\": {\"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}, \"yaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}, \"zaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}, \"bgcolor\": \"white\", \"caxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#EBF0F8\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#EBF0F8\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"<b>20_Customers_Savings_Algorithm_Total_Distance_6.81</b>\"}, \"width\": 1000, \"xaxis\": {\"title\": {\"text\": \"X coordinate\"}}, \"yaxis\": {\"title\": {\"text\": \"Y coordinate\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1b9db072-2f79-4089-a351-540b43eb9436');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay7Z1pFwHmG5"
      },
      "source": [
        "## Giving Custom Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9RV6u-yJRsZ"
      },
      "source": [
        "'''\n",
        "# Give coordinates of depot isted of X,Y\n",
        "depot=([X,Y])\n",
        "#Locations values input\n",
        "locations= ([[[x1,y1],\n",
        "              [x2,y2],\n",
        "              [x3,y3],\n",
        "              [x4,y4],\n",
        "              [x5,y5],\n",
        "              [x6,y6],\n",
        "              [x7,y7],\n",
        "              [x8,y8],\n",
        "              [x9,y9],\n",
        "              [x10,y10],\n",
        "              [x11,y11],\n",
        "              [x12,y12],\n",
        "              [x13,y13],\n",
        "              [x14,y14],\n",
        "              [x15,y15],\n",
        "              [x16,y16],\n",
        "              [x17,y17],\n",
        "              [x18,y18],\n",
        "              [x19,y19],\n",
        "              [x20,y20]]])\n",
        "#Give demand values matching the number of loaction values given\n",
        "demand=([[1,2,4,9,8,3,6,4,8,2,5,6,4,8,9,7,6,5,4,4]])\n",
        "#Capacities besed on number of locations values\n",
        "CAPACITIES = {10: 20.,\n",
        "              20: 30.,\n",
        "              30: 35.,\n",
        "              40: 40.,\n",
        "              50: 45.,\n",
        "              100: 50.}\n",
        "              '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDtdV-GAqUUa"
      },
      "source": [
        "'''\n",
        "# Normalize the data\n",
        "depot=tf.keras.utils.normalize(depot, order=2)\n",
        "locations=tf.keras.utils.normalize(locations, order=2)\n",
        "demand=demand/tf.cast(CAPACITIES[GRAPH_SIZE], tf.float32)\n",
        "# Converting the data into tensor shape\n",
        "depot=tf.convert_to_tensor(depot, dtype=tf.float32)\n",
        "locations=tf.convert_to_tensor(locations, dtype=tf.float32)\n",
        "demand=tf.convert_to_tensor(demand, dtype=tf.float32)\n",
        "\n",
        "# Above models can be used to get optimal using this tour\n",
        "tour=[depot,locations,demand]'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}